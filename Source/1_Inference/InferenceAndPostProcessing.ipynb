{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0c97d6f-be29-4d4e-9d4c-95df913abeaf",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44bc5b6-ee0e-46ec-9f08-fbef736ee6b7",
   "metadata": {},
   "source": [
    "## Load all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "375407ae-eb55-4fcd-b65e-1cf2fb890694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.9\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "print(fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "elementary-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "24e89830-8d12-449f-aab1-b0dab2d3b890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "import rioxarray as riox\n",
    "from rioxarray.merge import merge_arrays\n",
    "import json\n",
    "from py_linq import Enumerable\n",
    "import wget\n",
    "import shutil\n",
    "import multiprocessing as mp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "obvious-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "regional-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Helpers.MODIS8DaysHelper as mh\n",
    "import Helpers.GEEHelpers as GEEHelpers\n",
    "import Helpers.StaticFeaturesHelper as StaticFeaturesHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff87cc4b-434e-4796-8e42-b94dff3956bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Helpers.StaticFeaturesHelper' from '/home/jgiezendanner/UA/cvpr23-earthvision-CNN-LSTM-Inundation/Source/Helpers/StaticFeaturesHelper.py'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(mh)\n",
    "importlib.reload(GEEHelpers)\n",
    "importlib.reload(StaticFeaturesHelper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d7a263fa-20bb-4f9c-bbd0-1b67de2cb1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ModelClasses.Model import CNNLSTM as CNNLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c589b4bd-cd2b-41f2-84ea-d7ab6c1251f5",
   "metadata": {},
   "source": [
    "## Define Data Path and load data references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "477851ef-0c86-49f3-a570-beef36e5ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = Path('../../Data/InferenceData/Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "064b639c-fb0f-467f-97c6-4f65140b27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmDF = pd.read_json(dataPath/'lstmFilesInference.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d097baed-1ad4-497e-985b-b35be0892cf5",
   "metadata": {},
   "source": [
    "## Define number of time steps for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0379c033-5621-429b-ab37-45a04637a6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSteps = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89da150-bd7e-4f8f-80ef-a3d9d45ab7fd",
   "metadata": {},
   "source": [
    "## Define functions to access file path and open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1cef4603-403d-4191-bc13-cf85f1710cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStaticFeaturesFromLabel(filePath):\n",
    "    elevation = np.expand_dims(StaticFeaturesHelper.getScaledElevation(filePath.parent.parent/'Elevation'/('_'.join(filePath.stem.split('_')[0:2]) + '.tif')), 0)\n",
    "    slopeFile = np.expand_dims(StaticFeaturesHelper.getScaledHAND(filePath.parent.parent/'Slope'/('_'.join(filePath.stem.split('_')[0:2]) + '.tif')), 0)\n",
    "    hand = np.expand_dims(StaticFeaturesHelper.getSlope(filePath.parent.parent/'HAND'/('_'.join(filePath.stem.split('_')[0:2]) + '.tif')), 0)\n",
    "    return np.concatenate((elevation, slopeFile, hand))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "039baecc-1f47-4a1d-a3be-76462eae76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModisFileFromLabel(filePath):\n",
    "    fileDir = filePath.parent\n",
    "    return [fileDir/item for item in lstmDF[lstmDF.File == filePath.name].FeatureFiles.values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "61ed3a37-15c1-4748-a0fc-cc4d5c9ab684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImage(file, bandsToUse):\n",
    "    return mh.getScaledModisFileBands(file, bandsToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "63e4fc17-0513-4fd9-bf55-21788387210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_features(fn, chnls=None):\n",
    "    bandsToUse = ['sur_refl_b03', 'sur_refl_b02', 'sur_refl_b01', 'sur_refl_b04', 'sur_refl_b05', 'sur_refl_b06', 'sur_refl_b07']\n",
    "    files = getModisFileFromLabel(fn)[0:timeSteps]\n",
    "    \n",
    "    staticFeatures = getStaticFeaturesFromLabel(fn)\n",
    "    \n",
    "    img = np.empty((0,32,32))\n",
    "    for file in files:\n",
    "        try:\n",
    "            newimg = readImage(file, bandsToUse)\n",
    "        except:\n",
    "            newimg = readImage(file, bandsToUse)\n",
    "        \n",
    "        newimg = np.concatenate((newimg, staticFeatures))\n",
    "        img = np.concatenate((newimg, img))\n",
    "    \n",
    "    img = img.astype(np.float32)\n",
    "    img = torch.from_numpy(img)\n",
    "    return img\n",
    "\n",
    "def open_mask(fn, chnls=None, cls=torch.Tensor):\n",
    "    img = np.expand_dims(rasterio.open(fn).read(1),0)\n",
    "    img = img.astype(np.float32)\n",
    "    npimg = torch.from_numpy(img)\n",
    "    clsImg = cls(npimg)\n",
    "    return clsImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e068d761-bbef-466a-b881-2e0905162e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiChannelTensorImage(TensorImage):\n",
    "    _show_args = ArrayImageBase._show_args\n",
    "    def show(self, channels=[1], ctx=None, vmin=None, vmax=None, **kwargs):\n",
    "        if len(channels) == 3: \n",
    "            return show_composite(self, channels=channels, ctx=ctx, vmin=vmin, vmax=vmax,\n",
    "                                  **{**self._show_args, **kwargs})\n",
    "    \n",
    "            \n",
    "    def norm(vals, vmin=None, vmax=None):\n",
    "        vmin = ifnone(vmin, np.quantile(vals, 0.01))\n",
    "        vmax = ifnone(vmax, np.quantile(vals, 0.99))\n",
    "        return (vals - vmin)/(vmax-vmin)\n",
    "\n",
    "    def show_composite(img, channels, ax=None, figsize=(3,3), title=None, scale=True,\n",
    "                       ctx=None, vmin=None, vmax=None, **kwargs)->plt.Axes:\n",
    "        \n",
    "        ax = ifnone(ax, ctx)\n",
    "        if ax is None: _, ax = plt.subplots()    \n",
    "        r, g, b = channels\n",
    "        tempim = img.data.cpu().numpy()\n",
    "        im = np.zeros((tempim.shape[1], tempim.shape[2], 3))\n",
    "        im[...,0] = tempim[r]\n",
    "        im[...,1] = tempim[g]\n",
    "        im[...,2] = tempim[b]\n",
    "        if scale: im = norm(im, vmin, vmax)\n",
    "        ax.imshow(im, **kwargs)\n",
    "        ax.axis('off')\n",
    "        if title is not None: ax.set_title(title)\n",
    "        return ax\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, fn, chans=None,  **kwargs) ->None:\n",
    "        return cls(open_features(fn=fn, chnls=chans))\n",
    "        \n",
    "    def __repr__(self): return f'{self.__class__.__name__} size={\"x\".join([str(d) for d in self.shape])}'\n",
    "    \n",
    "MultiChannelTensorImage.create = Transform(MultiChannelTensorImage.create)\n",
    "\n",
    "def MultiChannelImageBlock(cls=MultiChannelTensorImage, chans=None):\n",
    "    return TransformBlock(partial(cls.create, chans=chans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ca67af-b312-4a60-8c24-4b9e6aecc213",
   "metadata": {},
   "source": [
    "## create image blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7cf18395-f939-4cce-9f5d-dc96c0618652",
   "metadata": {},
   "outputs": [],
   "source": [
    "ImageBlock = MultiChannelImageBlock(chans=None)\n",
    "MaskBlock = TransformBlock(type_tfms=[partial(open_mask, cls=TensorImage)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee544584-a9e0-4d1e-9c14-68e46701a20e",
   "metadata": {},
   "source": [
    "## Get files for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "imported-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesForStudy(path, items=lstmDF.File.values):\n",
    "    return [path/('_'.join(item.split('_')[0:2]))/'MOD09A1.061'/item for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "15fccd7e-4dde-4b14-8ed0-d3cb08983437",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = getFilesForStudy(dataPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d574edf1-b2a1-45e5-8bfa-e65663409870",
   "metadata": {},
   "source": [
    "## Create data blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "moving-literacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DataBlock(blocks=(ImageBlock, MaskBlock),\n",
    "               get_items = getFilesForStudy\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850d4bde-096f-48f6-bea4-10cc37e85917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "662cb52c-0292-474f-b993-b5c18fa469e7",
   "metadata": {},
   "source": [
    "## Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "913a84fa-1765-4f68-b474-09398e5ca4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNLSTM(nbTimeSteps = timeSteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "piano-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = db.dataloaders(dataPath, num_workers=10, bs=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9e7eefa8-b4ba-4a07-bd8a-1f06bc77601e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_metric = [mse, rmse, R2Score()]\n",
    "loss_fn = MSELossFlat()\n",
    "learn = Learner(dl, model, loss_func = loss_fn, metrics=acc_metric, opt_func=ranger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a868ac-1644-4725-8874-6b3216291c71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9b0c30c-8474-48ac-9ca6-445e339187bd",
   "metadata": {},
   "source": [
    "### Get model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "14567488-4f72-4ec5-afad-a0e8f9be32bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFolder = Path('./models')\n",
    "modelFolder.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a48e7cf0-94fc-4d23-a356-4428c75b529c",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadLink = \"https://github.com/GieziJo/cvpr23-earthvision-CNN-LSTM-Inundation/releases/download/v1.0.0/ModelWeights.zip\"\n",
    "zipFilePath = modelFolder/'ModelWeights.zip'\n",
    "wget.download(downloadLink, out = (zipFilePath).as_posix())\n",
    "shutil.unpack_archive(zipFilePath, modelFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "b83171f4-7d45-4ec2-af1d-1bf6b9411d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelFolder = Path('./ModelWeights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376aaf8f-95df-4162-8403-79aea6fcee5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e722a454-663d-4c5e-960b-bc70cf1198e1",
   "metadata": {},
   "source": [
    "### Prepare output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d5173568-8d42-41f9-9c98-53b2b835f969",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFolder = Path('./InferredData')\n",
    "outputFolder.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "outputFolder_pickleData = outputFolder/'PickleData'\n",
    "outputFolder_pickleData.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "outputFolder_individualTifs = outputFolder/'IndividualTifs'\n",
    "outputFolder_individualTifs.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "outputFolder_fullTifs = outputFolder/'FullTifs'\n",
    "outputFolder_fullTifs.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8994b6bf-9e3e-4867-8ad4-59c7f718cd8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824d6e45-c42e-4dfa-87ca-3c5cf64a1627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0203e80b-6c9f-446d-a80f-de1e13477aac",
   "metadata": {},
   "source": [
    "### Run inference and save results as raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "53ee6dce-723b-47d4-8949-dc3b7ce6b774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define raster creation function\n",
    "def processResultAsRaster(k, items, targetPath, preds):\n",
    "    item = items[k]\n",
    "    # new file target path\n",
    "    fileTargetPath = targetPath/('_'.join(item.stem.split('_')[0:2]))\n",
    "    fileTargetPath.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "    # new file\n",
    "    targetFile = fileTargetPath/item.name\n",
    "    if targetFile.exists():\n",
    "        return\n",
    "    \n",
    "    with rasterio.open(item) as r:\n",
    "        profile = r.profile.copy()\n",
    "        profile.update(count = 1)\n",
    "        with rasterio.open(targetFile, 'w', **profile) as dst:\n",
    "            dst.write(preds[k,::],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786417d0-4446-4289-9cb8-17cb71e564f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5c5c34-49c6-4a79-bfde-f39a6e3f2a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "c9217be6-a615-43e2-8c7e-233f5e30f3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dl = learn.dls.test_dl(items)\n",
    "\n",
    "# run inference for each leave-out year\n",
    "for year in range(2017,2022):\n",
    "    featurePicklePath = outputFolder_pickleData/(str(year) + '_Features')\n",
    "    predictionPicklePath = outputFolder_pickleData/(str(year) + '_Infered')\n",
    "                                                 \n",
    "    outputFolder_individualTifs_year = outputFolder_individualTifs/(str(year))\n",
    "    \n",
    "    # only run inference if pickle files don't exist\n",
    "    if not (featurePicklePath.exists() and predictionPicklePath.exists()):\n",
    "    \n",
    "        # load model for leave-out year\n",
    "        modelNamePath = modelFolder/str(year)\n",
    "        learn.load(modelNamePath)\n",
    "\n",
    "        # infer for all items\n",
    "        preds, _ = learn.get_preds(dl=test_dl)\n",
    "        preds = preds.squeeze()\n",
    "\n",
    "        # save pickel files in case something goes wrong\n",
    "        with open(featurePicklePath,\"wb\") as f:\n",
    "            pickle.dump(items, f)\n",
    "        with open(predictionPicklePath,\"wb\") as f:\n",
    "            pickle.dump(preds, f)\n",
    "        \n",
    "    else:\n",
    "        with open(predictionPicklePath, \"rb\") as f:\n",
    "            preds = np.array(pickle.load(f))\n",
    "        \n",
    "    # process results as tifs in parallel\n",
    "    func_part = partial(processResultAsRaster, items=items, targetPath=outputFolder_individualTifs_year, preds=preds)\n",
    "    _ = mp.Pool(10).map(func_part, range(len(items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630fbfe-711b-4e6c-9508-1f24e7a20f52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b7697f5-5789-4275-b477-d52ca991b530",
   "metadata": {},
   "source": [
    "## Results Post-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0536dd5-ec51-4a26-842f-d2a38e0d47a3",
   "metadata": {},
   "source": [
    "### create bangladesh full raster for each cross validated year and each time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a21b1759-04e2-410d-b656-924ff6dcf209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRasterForTime(time, files, targetPath):\n",
    "    \n",
    "    fileName = targetPath/(str(time) + '.tif')\n",
    "    if fileName.exists():\n",
    "        return\n",
    "    \n",
    "    filesForTime = Enumerable(files).where(lambda item: int(item.stem.split('_')[2]) == time)\n",
    "    rasters = list(map(lambda item: riox.open_rasterio(item), filesForTime))\n",
    "    \n",
    "    gt = rasters[0].rio.transform()\n",
    "    res = (gt[0], -gt[4])\n",
    "    crs = str(rasters[0].rio.crs)\n",
    "    \n",
    "    merged_raster = merge_arrays(dataarrays = rasters, res = res, crs=crs, nodata = -9999)\n",
    "    \n",
    "    merged_raster.rio.to_raster(fileName)\n",
    "    \n",
    "    rasters = list(map(lambda item: item.close(), rasters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e9fa5e90-5d18-4409-9bd9-9ea65e52be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = np.sort(np.unique(list(map(lambda item: int(item.stem.split('_')[2]), items))))\n",
    "\n",
    "for year in range(2017,2022):\n",
    "    outputFolder_fullTifs_year = outputFolder_fullTifs/(str(year))\n",
    "    outputFolder_fullTifs_year.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    outputFolder_individualTifs_year = outputFolder_individualTifs/(str(year))\n",
    "    files = Enumerable(outputFolder_individualTifs_year.rglob(\"*\")).where(lambda p: p.suffix == '.tif').to_list()\n",
    "    \n",
    "    mp.Pool(10).map(partial(createRasterForTime, files = files, targetPath=outputFolder_fullTifs_year), times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77165a48-b909-4ebe-8eb9-8e6bbebb0faf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d946a5d8-f432-4391-97cf-bd870fea2e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4dc1a524-64d1-4b1c-bbd7-009a483cb89a",
   "metadata": {},
   "source": [
    "### create bangladesh ensemble full raster for each time step from cross-validated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "ee8fee01-9de1-4750-a279-ad2ab549d638",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputFolder_fullTifs_ensemble = outputFolder_fullTifs/'Ensemble'\n",
    "outputFolder_fullTifs_ensemble.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "for time in times:\n",
    "    fileName = outputFolder_fullTifs_ensemble/(str(time) + '.tif')\n",
    "    \n",
    "    if fileName.exists():\n",
    "        continue\n",
    "    \n",
    "    vals = []\n",
    "    \n",
    "    for year in range(2017,2022):\n",
    "        file = outputFolder_fullTifs/(str(year))/(str(time) + '.tif')\n",
    "        with riox.open_rasterio(file) as r:\n",
    "            vals.append(r.values)\n",
    "    \n",
    "            if year == 2021:\n",
    "                out = np.median(np.array(vals), axis=0)\n",
    "                out[out < 0] = -9999\n",
    "                \n",
    "                r.values = out\n",
    "                r.rio.to_raster(fileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15b5c22-dc36-4fa1-8b3d-5b774ee07d6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
