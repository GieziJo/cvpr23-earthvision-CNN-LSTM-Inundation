{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54891470-b955-49af-b7bd-07be107712e6",
   "metadata": {},
   "source": [
    "# Training and Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3428d2c8-984e-42c3-81c5-220bd647d1d5",
   "metadata": {},
   "source": [
    "## Load all required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "579799e9-3336-453c-b933-2d35cbffbf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336ea0f2-c8f8-4406-bb68-7153f38df3bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.9\n"
     ]
    }
   ],
   "source": [
    "import fastai\n",
    "print(fastai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elementary-vault",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba296f3-c3c1-40a4-b782-fe5e143b81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "import rasterio.plot\n",
    "import json\n",
    "from py_linq import Enumerable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "495478f3-e482-411c-a674-a74bd6ce8cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3995a92f-be4d-4acb-bf1d-651a572affc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = logging.getLogger()\n",
    "log.setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "obvious-extra",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regional-orientation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import Helpers.MODIS8DaysHelper as mh\n",
    "import Helpers.GEEHelpers as GEEHelpers\n",
    "import Helpers.StaticFeaturesHelper as StaticFeaturesHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3328d6d7-f636-4293-a08e-9a9fd095137c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'Helpers.StaticFeaturesHelper' from '/home/jgiezendanner/UA/cvpr23-earthvision-CNN-LSTM-Inundation/Source/Helpers/StaticFeaturesHelper.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(mh)\n",
    "importlib.reload(GEEHelpers)\n",
    "importlib.reload(StaticFeaturesHelper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf89542-32bd-4c7b-93b9-7e7d2e077dfa",
   "metadata": {},
   "source": [
    "## Define Data Path and load data references"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "098dbc28-c469-43e3-a0c4-d23761faffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = Path('../../Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "064b639c-fb0f-467f-97c6-4f65140b27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstmDF = pd.read_json(dataPath/'lstmFiles.json') # dataframe for LSTM with corresponding data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5a72cb-5052-4bd6-aa20-0fb0c18a0629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeb3db09-fff1-4b1a-93ea-3aeb3b14fe4a",
   "metadata": {},
   "source": [
    "## Define functions to access file path and open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbfdc095-58b4-439a-9d01-bd9d01d3dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStaticFeaturesFromLabel(filePath):\n",
    "    elevation = np.expand_dims(StaticFeaturesHelper.getScaledElevation(filePath.parent.parent/'Elevation'/('_'.join(filePath.stem.split('_')[0:2]) + '.tif')), 0)\n",
    "    slopeFile = np.expand_dims(StaticFeaturesHelper.getScaledHAND(filePath.parent.parent/'Slope'/('_'.join(filePath.stem.split('_')[0:2]) + '.tif')), 0)\n",
    "    hand = np.expand_dims(StaticFeaturesHelper.getSlope(filePath.parent.parent/'HAND'/('_'.join(filePath.stem.split('_')[0:2]) + '.tif')), 0)\n",
    "    return np.concatenate((elevation, slopeFile, hand))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1540353d-c714-4e16-a17a-9407a983b02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getModisFileFromLabel(filePath):\n",
    "    fileDir = filePath.parent.parent/\"MOD09A1.061\"\n",
    "    return [fileDir/item for item in lstmDF[lstmDF.File == filePath.name].FeatureFiles.values[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db502cd6-576b-4b35-bf5f-b006efeaa478",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readImage(file, bandsToUse):\n",
    "    return mh.getScaledModisFileBands(file, bandsToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9634c24d-05bf-48b0-a8d1-570593e5c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeSteps = 10\n",
    "# Open MODIS files and indices\n",
    "def open_features(fn, chnls=None):\n",
    "    # Stack MODIS time steps\n",
    "    bandsToUse = ['sur_refl_b03', 'sur_refl_b02', 'sur_refl_b01', 'sur_refl_b04', 'sur_refl_b05', 'sur_refl_b06', 'sur_refl_b07']\n",
    "    files = getModisFileFromLabel(fn)[0:timeSteps]\n",
    "    \n",
    "    staticFeatures = getStaticFeaturesFromLabel(fn)\n",
    "    \n",
    "    img = np.empty((0,32,32))\n",
    "    for file in files:\n",
    "        try:\n",
    "            newimg = readImage(file, bandsToUse)\n",
    "        except:\n",
    "            newimg = readImage(file, bandsToUse)\n",
    "        \n",
    "        newimg = np.concatenate((newimg, staticFeatures))\n",
    "        img = np.concatenate((newimg, img))\n",
    "    \n",
    "    img = img.astype(np.float32)\n",
    "    img = torch.from_numpy(img)\n",
    "    return img\n",
    "\n",
    "# open ground truth\n",
    "def open_mask(fn, chnls=None, cls=torch.Tensor):\n",
    "    img = np.expand_dims(rasterio.open(fn).read(1),0)\n",
    "    img = img.astype(np.float32)\n",
    "    npimg = torch.from_numpy(img)\n",
    "    clsImg = cls(npimg)\n",
    "    return clsImg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfc6910-3a27-481b-b799-5b6291c257f6",
   "metadata": {},
   "source": [
    "## define function wot work with multi-band data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df48333e-f04b-41e3-80c1-24427b895a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiChannelTensorImage(TensorImage):\n",
    "    _show_args = ArrayImageBase._show_args\n",
    "    def show(self, channels=[1], ctx=None, vmin=None, vmax=None, **kwargs):\n",
    "        if len(channels) == 3: \n",
    "            return show_composite(self, channels=channels, ctx=ctx, vmin=vmin, vmax=vmax,\n",
    "                                  **{**self._show_args, **kwargs})\n",
    "    \n",
    "            \n",
    "    def norm(vals, vmin=None, vmax=None):\n",
    "        vmin = ifnone(vmin, np.quantile(vals, 0.01))\n",
    "        vmax = ifnone(vmax, np.quantile(vals, 0.99))\n",
    "        return (vals - vmin)/(vmax-vmin)\n",
    "\n",
    "    def show_composite(img, channels, ax=None, figsize=(3,3), title=None, scale=True,\n",
    "                       ctx=None, vmin=None, vmax=None, **kwargs)->plt.Axes:\n",
    "        \n",
    "        ax = ifnone(ax, ctx)\n",
    "        if ax is None: _, ax = plt.subplots()    \n",
    "        r, g, b = channels\n",
    "        tempim = img.data.cpu().numpy()\n",
    "        im = np.zeros((tempim.shape[1], tempim.shape[2], 3))\n",
    "        im[...,0] = tempim[r]\n",
    "        im[...,1] = tempim[g]\n",
    "        im[...,2] = tempim[b]\n",
    "        if scale: im = norm(im, vmin, vmax)\n",
    "        ax.imshow(im, **kwargs)\n",
    "        ax.axis('off')\n",
    "        if title is not None: ax.set_title(title)\n",
    "        return ax\n",
    "\n",
    "    @classmethod\n",
    "    def create(cls, fn, chans=None,  **kwargs) ->None:\n",
    "        return cls(open_features(fn=fn, chnls=chans))\n",
    "        \n",
    "    def __repr__(self): return f'{self.__class__.__name__} size={\"x\".join([str(d) for d in self.shape])}'\n",
    "    \n",
    "MultiChannelTensorImage.create = Transform(MultiChannelTensorImage.create)\n",
    "\n",
    "def MultiChannelImageBlock(cls=MultiChannelTensorImage, chans=None):\n",
    "    return TransformBlock(partial(cls.create, chans=chans))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745692df-5418-4d81-80ec-4d24e6012421",
   "metadata": {},
   "source": [
    "## create image blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e8901c6-1bde-487b-bb21-829601cf2ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create image blocks\n",
    "ImageBlock = MultiChannelImageBlock(chans=None)\n",
    "MaskBlock = TransformBlock(type_tfms=[partial(open_mask, cls=TensorImage)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8be7bc-5228-4ddb-8ce5-88c3241f3121",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "00a2c0f3-9661-49a8-bb9d-9ca901f0e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FileSplitter(leaveOutYear):\n",
    "    def _func(x): return int(x.stem.split('_')[2]) >= int(GEEHelpers.GetGEETimeStampFromDate(leaveOutYear,1,1))\\\n",
    "                        and int(x.stem.split('_')[2]) <= int(GEEHelpers.GetGEETimeStampFromDate(leaveOutYear,12,31))\n",
    "    def _inner(o, **kwargs): return FuncSplitter(_func)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e58986a-c5fa-4e21-a27f-dc1d93aae098",
   "metadata": {},
   "source": [
    "## define function to get dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "imported-transcription",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesForStudy(path, items=lstmDF.File.values):\n",
    "    return [path/('_'.join(item.split('_')[0:2]))/'Sen1FractionInundatedArea'/item for item in items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "15fccd7e-4dde-4b14-8ed0-d3cb08983437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this to check if items are found\n",
    "# items = getFilesForStudy(dataPath, lstmDF.File.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa022ce8-066f-48d0-916a-0a6993aca4ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112ee282-6f7f-4268-a331-1d957106795e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed29d63b-d46c-467b-8f51-6f74eee01664",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f55afd3-04ca-4826-b93e-8a37fdb13c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, nbFeatures=10, initSize=32, nbLayers=1, nbTimeSteps=timeSteps, input_size=32*32, hidden_size=32*32):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.nbFeatures = nbFeatures\n",
    "        self.input_size = input_size\n",
    "        self.nbTimeSteps = nbTimeSteps\n",
    "        \n",
    "        # define helper functions for convolutions, either single convolution, or combined with res block\n",
    "        def conv2_single(ni,nf): return nn.Conv2d(ni, nf, kernel_size=3, padding=1, padding_mode='reflect', stride=1)\n",
    "        def conv2(ni,nf): return nn.Conv2d(ni, nf, groups=nbTimeSteps, kernel_size=3, padding=1, padding_mode='reflect', stride=1)\n",
    "        def conv2_and_res(ni, nf): return nn.Sequential(conv2(ni,nf), ResBlock(2, ni, nf, groups=nbTimeSteps, stride=1))\n",
    "        \n",
    "        # Create CNN A\n",
    "        # note that groups are defined by number of time steps, i.e. each time step is applied the same CNN separatly\n",
    "        self.cnn = nn.Sequential(\n",
    "            conv2(nbFeatures*nbTimeSteps,nbTimeSteps*initSize)\n",
    "        )\n",
    "        \n",
    "        for k in range(nbLayers):\n",
    "            self.cnn = self.cnn.append(conv2_and_res(nbTimeSteps*initSize * 4**k, nbTimeSteps*(initSize * 2) * 4**k))\n",
    "        self.cnn = self.cnn.append(conv2(nbTimeSteps*(initSize * 2) * 4**(nbLayers-1)* 2,nbTimeSteps*1))\n",
    "        \n",
    "        # Create LSTM\n",
    "        self.LSTM = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True, bidirectional=False)\n",
    "        \n",
    "        # Create transpose convolution\n",
    "        self.convTrans = nn.ConvTranspose2d(1024,1,kernel_size=32)\n",
    "        \n",
    "        # Set the output to be a single convolution and a sigmoid\n",
    "        self.outLayer = nn.Sequential(conv2_single(2,1), SigmoidRange(0,1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # get size of problem\n",
    "        batchSize = x.shape[0]\n",
    "        imgSize = x.shape[2:4]\n",
    "        \n",
    "        # pass all time steps through the CNN\n",
    "        x = self.cnn(x)\n",
    "        # extract time step 0\n",
    "        x_now = x[:,0,::].view((batchSize,1,imgSize[0],imgSize[1]))\n",
    "        # pass time step -1 to -9 through lstm\n",
    "        x, (_,_) = self.LSTM(x[:,1:,::].view((batchSize,self.nbTimeSteps-1,-1)))\n",
    "        # extract result and pass through transpose convolution\n",
    "        x = x[:,-1,:].view((batchSize,-1,1,1))\n",
    "        x = self.convTrans(x)\n",
    "        # concatenate lstm output and time step t\n",
    "        x = torch.cat((x_now,x),1)\n",
    "        # pass output through output layer\n",
    "        x = self.outLayer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59775b97-9443-4f0e-b68c-9ca4498a3ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05085e75-de2a-4cbf-8be7-612c3be32d9e",
   "metadata": {},
   "source": [
    "## Define model params, output dir and tfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a6ae714d-6657-4ef6-a160-c59c3c661bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(Path('models')/'CNNLSTM').mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "62aaf0b2-baaf-4dad-8b3a-537ad25050b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_tfms = [Rotate(), Flip(), Dihedral()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e87505d-e2ec-4a89-aa57-04529ee6401e",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d405346-bb55-420a-92ba-06cd69adc35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(leaveOutYear):\n",
    "    \n",
    "    # Define data loaders\n",
    "    db = DataBlock(blocks=(ImageBlock, MaskBlock),\n",
    "               get_items = getFilesForStudy,\n",
    "               splitter=FileSplitter(leaveOutYear),\n",
    "               batch_tfms = batch_tfms,\n",
    "              )\n",
    "\n",
    "    dl = db.dataloaders(dataPath, num_workers=20, bs=128)#os.cpu_count()-20, num_workers=20, num_workers=int((os.cpu_count()-20) / 3)\n",
    "\n",
    "    # Set model metrics\n",
    "    acc_metric = [mse, rmse, R2Score()]\n",
    "    loss_fn = MSELossFlat()\n",
    "\n",
    "    # create model\n",
    "    model = Net()\n",
    "\n",
    "    # create learner\n",
    "    learn = Learner(dl, model, loss_func = loss_fn, metrics=acc_metric, opt_func=ranger, cbs=CSVLogger(append=True, fname='history_' + str(leaveOutYear) + '.csv'))\n",
    "\n",
    "    # in case we want to load a previous iteration of learning (also modify the for loop below)\n",
    "    # learn_iter = 0\n",
    "    # learn.load(\"'CNNLSTM/' + str(leaveOutYear) + str(0), with_opt=False)\n",
    "\n",
    "    # in case we want to find the learning rate valley\n",
    "    # lr = learn.lr_find().valley\n",
    "    # print(lr)\n",
    "\n",
    "    lrs = [.001, .0001, .00001]\n",
    "    # epochs = [20, 5, 5]\n",
    "    epochs = [3, 1, 1]\n",
    "\n",
    "    # train\n",
    "    for k in range(3):\n",
    "        lrslice = slice(lrs[k])\n",
    "        learn.fit_flat_cos(epochs[k], lr=lrslice)\n",
    "        learn.save('CNNLSTM/' + str(leaveOutYear) + \"_\" + str(k))\n",
    "        print('done saving ' + str(k))\n",
    "\n",
    "    print('Done with Leave-out year ' + str(leaveOutYear))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db084ffc-a918-4eb4-b0e0-b2fef714904e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loop through cross validated years\n",
    "for leaveOutYear in range(2017, 2022):\n",
    "    print(' Starting Leave-out year ' + str(leaveOutYear))\n",
    "    train(leaveOutYear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbce5cf4-23fb-49f7-82eb-34c9f4940e96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1313297f-667f-442e-a506-2086289177b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886eb264-6767-4843-884f-e88f6b341019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b3558-b2fa-4407-bd3c-12941e5bf122",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b038c6-9bff-48d0-8693-a80245338cec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
